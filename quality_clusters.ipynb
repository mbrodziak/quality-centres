{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wybierz zbiór danych:\n",
      "    1 - zbiór Cars\n",
      "    2 - zbiór CC General\n",
      "    3 - zbiór Sales Transaction Dataset Weekly\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podaj liczbę skupień: \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wybierz miarę podobieństwa:\n",
      "    1 - odległość Euklidesowa\n",
      "    2 - odległość Manhattan\n",
      "    3 - odległość Czebyszewa\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wybierz indeks miary:\n",
      "    1 - indeks Dunna\n",
      "    2 - indeks Daviesa-Bouldina\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wybrano zbiór Cars\n",
      "Podana liczba skupień:  2\n",
      "Wybrano odległość Euklidesową\n",
      "Wybrano indeks Dunna\n",
      "\n",
      "Index Dunna:\n",
      "0.02336187977538766\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from scipy.spatial import distance\n",
    "\n",
    "print('''Wybierz zbiór danych:\n",
    "    1 - zbiór Cars\n",
    "    2 - zbiór CC General\n",
    "    3 - zbiór Sales Transaction Dataset Weekly''')\n",
    "dataset = input()\n",
    "\n",
    "print(\"Podaj liczbę skupień: \")\n",
    "k = input()\n",
    "k = int(k)\n",
    "\n",
    "print('''Wybierz miarę podobieństwa:\n",
    "    1 - odległość Euklidesowa\n",
    "    2 - odległość Manhattan\n",
    "    3 - odległość Czebyszewa''')\n",
    "kind_of_distance = input()\n",
    "\n",
    "print('''Wybierz indeks miary:\n",
    "    1 - indeks Dunna\n",
    "    2 - indeks Daviesa-Bouldina''')\n",
    "kind_of_index = input()\n",
    "\n",
    "print()\n",
    "\n",
    "if dataset == \"1\":\n",
    "    data = pd.read_csv('./data/cars_p.csv', delimiter=\";\")\n",
    "    print(\"Wybrano zbiór Cars\")\n",
    "elif dataset == \"2\":\n",
    "    data = pd.read_csv('./data/CC GENERAL_p.csv', delimiter=\";\")\n",
    "    print(\"Wybrano zbiór CC General\")\n",
    "elif dataset == \"3\":\n",
    "    data = pd.read_csv('./data/Sales_Transactions_Dataset_Weekly_p.csv', delimiter=\";\")\n",
    "    print(\"Wybrano zbiór Sales Transaction Dataset Weekly\")\n",
    "else:\n",
    "    raise ValueError(\"Pod tym numerem nie ma zbioru danych!\")\n",
    "    \n",
    "data = data.fillna(data.mean())\n",
    "\n",
    "print(\"Podana liczba skupień: \", k)\n",
    "\n",
    "if kind_of_distance == \"1\":\n",
    "    print(\"Wybrano odległość Euklidesową\")\n",
    "elif kind_of_distance == \"2\":\n",
    "    print(\"Wybrano odległość Manhattan\")\n",
    "elif kind_of_distance == \"3\":\n",
    "    print(\"Wybrano odległość Czebyszewa\")\n",
    "    \n",
    "if kind_of_index == \"1\":\n",
    "    print(\"Wybrano indeks Dunna\")\n",
    "elif kind_of_index == \"2\":\n",
    "    print(\"Wybrano indeks Daviesa-Bouldina\")\n",
    "    \n",
    "print()\n",
    "\n",
    "centroid = []\n",
    "centroids = []\n",
    "distances = []\n",
    "p_distances = []\n",
    "clusters = []\n",
    "p_clusters = []\n",
    "column_clusters = []\n",
    "part_clusters = []\n",
    "all_clusters = []\n",
    "min_val = 0\n",
    "min_in = 0\n",
    "c = 0\n",
    "mean = 0\n",
    "means = []\n",
    "is_migrate = True\n",
    "dist_outside = []\n",
    "dist_inside = []\n",
    "che_dist_outside = []\n",
    "che_dist_inside = []\n",
    "min_value = 0\n",
    "max_value = 0\n",
    "index_dunna = 0\n",
    "sum_inside = 0\n",
    "p = 0\n",
    "p_all = []\n",
    "p_all_sum = []\n",
    "p_all_sum_c = []\n",
    "dist_cen = []\n",
    "dist_centroids = []\n",
    "r = []\n",
    "r_max = 0\n",
    "db_index = 0\n",
    "\n",
    "\n",
    "def calculate_distances():\n",
    "    global p_distances\n",
    "    if kind_of_distance == \"1\":\n",
    "        for i in range(k):\n",
    "            distances.append(euclidean_distances(data, [centroids[i]]))\n",
    "    elif kind_of_distance == \"2\":\n",
    "        for i in range(k):\n",
    "            distances.append(manhattan_distances(data, [centroids[i]]))\n",
    "    elif kind_of_distance == \"3\":\n",
    "        for i in range(k):\n",
    "            for j in range(len(data)):\n",
    "                p_distances.append(distance.chebyshev([data.iloc[j]], [centroids[i]]))\n",
    "            distances.append(p_distances)\n",
    "            p_distances = []\n",
    "    else:\n",
    "        raise ValueError(\"Pod tym numerem nie ma miary podobieństwa!\")\n",
    "\n",
    "        \n",
    "def calculate_dunn_index():\n",
    "    global max_value, che_dist_outside, che_dist_inside\n",
    "    if kind_of_distance == \"1\":\n",
    "        for i in range(len(all_clusters)):\n",
    "            for j in range(i + 1, len(all_clusters)):\n",
    "                if len(all_clusters[i]) != 0 and len(all_clusters[j]) != 0:\n",
    "                    dist_outside.append(euclidean_distances(all_clusters[i], all_clusters[j]))\n",
    "\n",
    "        for i in range(len(all_clusters)):\n",
    "            if len(all_clusters[i]) != 0:\n",
    "                dist_inside.append(euclidean_distances(all_clusters[i], all_clusters[i]))\n",
    "    elif kind_of_distance == \"2\":\n",
    "        for i in range(len(all_clusters)):\n",
    "            for j in range(i + 1, len(all_clusters)):\n",
    "                if len(all_clusters[i]) != 0 and len(all_clusters[j]) != 0:                \n",
    "                    dist_outside.append(manhattan_distances(all_clusters[i], all_clusters[j]))\n",
    "\n",
    "        for i in range(len(all_clusters)):\n",
    "            if len(all_clusters[i]) != 0:\n",
    "                dist_inside.append(manhattan_distances(all_clusters[i], all_clusters[i]))\n",
    "    elif kind_of_distance == \"3\":\n",
    "        for i in range(len(all_clusters)):\n",
    "            for j in range(i + 1, len(all_clusters)):\n",
    "                for l in range(len(all_clusters[i])):\n",
    "                    for m in range(len(all_clusters[j])):\n",
    "                        che_dist_outside.append(distance.chebyshev(all_clusters[i][l], all_clusters[j][m]))    \n",
    "                dist_outside.append([che_dist_outside])\n",
    "                che_dist_outside = []\n",
    "\n",
    "        for i in range(len(all_clusters)):\n",
    "            for j in range(len(all_clusters[i]) - 1):\n",
    "                for l in range(j + 1, len(all_clusters[i])):\n",
    "                    che_dist_inside.append(distance.chebyshev(all_clusters[i][j], all_clusters[i][l]))\n",
    "            dist_inside.append([che_dist_inside])\n",
    "            che_dist_inside = []\n",
    "\n",
    "    if len(dist_outside) == 0 or (kind_of_distance == \"3\" and dist_outside == [[[]]]):\n",
    "        min_value = 0\n",
    "    else:\n",
    "        if kind_of_distance == \"3\":\n",
    "            if dist_outside[0] == [[]]:\n",
    "                min_value = 1000000000\n",
    "            else: \n",
    "                min_value = dist_outside[0][0][0]\n",
    "        else:    \n",
    "            min_value = dist_outside[0][0][0]\n",
    "        for i in range(len(dist_outside)):\n",
    "            for j in range(len(dist_outside[i])):\n",
    "                for l in range(len(dist_outside[i][j])):\n",
    "                    if dist_outside[i][j][l] < min_value:\n",
    "                        min_value = dist_outside[i][j][l]\n",
    "\n",
    "    for i in range(len(dist_inside)):\n",
    "        for j in range(len(dist_inside[i])):\n",
    "            for l in range(len(dist_inside[i][j])):\n",
    "                if dist_inside[i][j][l] > max_value:\n",
    "                    max_value = dist_inside[i][j][l]\n",
    "\n",
    "    index_dunna = min_value / max_value\n",
    "    print(\"Index Dunna:\")\n",
    "    print(index_dunna)\n",
    "\n",
    "\n",
    "def calculate_davies_bouldin_index():\n",
    "    global sum_inside, sum_all, r_max, dist_cen, che_dist_inside, p_all_sum, db_index\n",
    "    if k == 1:\n",
    "        db_index = 0\n",
    "    else: \n",
    "        if kind_of_distance == \"1\":\n",
    "            for i in range(len(all_clusters)):\n",
    "                if len(all_clusters[i]) != 0:\n",
    "                    dist_inside.append(euclidean_distances(all_clusters[i], [centroids[i]]))\n",
    "\n",
    "            for i in range(len(centroids)):\n",
    "                for j in range(len(centroids)):\n",
    "                    if i != j:\n",
    "                        dist_cen.append(euclidean_distances([centroids[i]], [centroids[j]]))\n",
    "                dist_centroids.append(dist_cen)\n",
    "                dist_cen = []\n",
    "        elif kind_of_distance == \"2\":\n",
    "            for i in range(len(all_clusters)):\n",
    "                if len(all_clusters[i]) != 0:\n",
    "                    dist_inside.append(manhattan_distances(all_clusters[i], [centroids[i]]))\n",
    "\n",
    "            for i in range(len(centroids)):\n",
    "                for j in range(len(centroids)):\n",
    "                    if i != j:\n",
    "                        dist_cen.append(manhattan_distances([centroids[i]], [centroids[j]]))\n",
    "                dist_centroids.append(dist_cen)\n",
    "                dist_cen = []\n",
    "        elif kind_of_distance == \"3\": \n",
    "            for i in range(len(all_clusters)):\n",
    "                if len(all_clusters[i]) != 0:\n",
    "                    for j in range(len(all_clusters[i])):\n",
    "                        che_dist_inside.append(distance.chebyshev(all_clusters[i][j], [centroids[i]]))\n",
    "                dist_inside.append(che_dist_inside)\n",
    "                che_dist_inside = []\n",
    "\n",
    "            for i in range(len(centroids)):\n",
    "                for j in range(len(centroids)):\n",
    "                    if i != j:\n",
    "                        dist_cen.append(distance.chebyshev([centroids[i]], [centroids[j]]))\n",
    "                dist_centroids.append(dist_cen)\n",
    "                dist_cen = []\n",
    "\n",
    "        for i in range(len(dist_inside)):\n",
    "            sum_inside = 0\n",
    "            p = 0\n",
    "            for j in range(len(dist_inside[i])):\n",
    "                sum_inside += dist_inside[i][j]\n",
    "            if kind_of_distance == \"3\":\n",
    "                try:\n",
    "                    p = sum_inside * (1 / len(dist_inside[i]))\n",
    "                except ZeroDivisionError:\n",
    "                    p = 0\n",
    "            else:\n",
    "                p = sum_inside * (1 / len(dist_inside[i]))\n",
    "            p_all.append(p)\n",
    "\n",
    "        if kind_of_distance == \"1\" or kind_of_distance == \"2\":\n",
    "            if len(p_all) < len(centroids):\n",
    "                tab = [0]\n",
    "                cen = []\n",
    "                for j in range(len(data.columns)):\n",
    "                    cen.append(0)\n",
    "\n",
    "                for i in range(len(centroids)):\n",
    "                    if centroids[i] == cen:\n",
    "                        p_all.insert(i, tab)\n",
    "\n",
    "\n",
    "        for i in range(len(p_all)):\n",
    "            for j in range(len(p_all)):\n",
    "                if i != j:\n",
    "                    if p_all[i] == [0] and p_all[j] == [0]:\n",
    "                        p_all_sum.append([0])\n",
    "                    else:\n",
    "                        p_all_sum.append(p_all[i] + p_all[j]) \n",
    "            p_all_sum_c.append(p_all_sum)\n",
    "            p_all_sum = []\n",
    "\n",
    "        for i in range(len(p_all_sum_c)):\n",
    "            r = []\n",
    "            for j in range(len(p_all_sum_c[i])):\n",
    "                if dist_centroids[i][j] == 0:\n",
    "                    r.append([0])\n",
    "                else:\n",
    "                    r.append(p_all_sum_c[i][j] / dist_centroids[i][j])\n",
    "            r_max += max(r)\n",
    "\n",
    "\n",
    "        db_index = (1 / k) * r_max\n",
    "    print(\"Index Daviesa-Bouldina: \")\n",
    "    print(db_index)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for i in range(k):\n",
    "        rand = random.randint(0, len(data) - 1)\n",
    "        for j in range(len(data.columns)):\n",
    "            centroid.append(data.iloc[rand][j])\n",
    "        centroids.append(centroid)\n",
    "        centroid = []\n",
    "\n",
    "    calculate_distances()\n",
    "\n",
    "    while is_migrate:\n",
    "        p_clusters = clusters\n",
    "        clusters = []\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            min_val = distances[0][i]\n",
    "            min_in = 0\n",
    "            for j in range(1, len(distances)):\n",
    "                if distances[j][i] < min_val:\n",
    "                    min_val = distances[j][i]\n",
    "                    min_in = j\n",
    "            clusters.append(min_in)\n",
    "\n",
    "        if clusters == p_clusters:\n",
    "            is_migrate = False\n",
    "        else:\n",
    "            centroids = []\n",
    "            all_clusters = []\n",
    "\n",
    "            for i in range(k):\n",
    "                part_clusters = []\n",
    "                for j in range(len(clusters)):\n",
    "                    if clusters[j] == i:\n",
    "                        for l in range(len(data.columns)):\n",
    "                            column_clusters.append(data.at[j, data.columns[l]])\n",
    "                        part_clusters.append(column_clusters)\n",
    "                        column_clusters = []\n",
    "                all_clusters.append(part_clusters)\n",
    "\n",
    "            for i in range(len(all_clusters)):\n",
    "                for l in range(len(data.columns)):\n",
    "                    c = 0\n",
    "                    mean = 0\n",
    "                    for j in range (len(all_clusters[i])):\n",
    "                        c = c + all_clusters[i][j][l]\n",
    "                    if len(all_clusters[i]) > 0:\n",
    "                        mean = c / len(all_clusters[i])\n",
    "                    means.append(mean)\n",
    "                centroids.append(means)\n",
    "                means = []\n",
    "\n",
    "            distances = []\n",
    "            calculate_distances()\n",
    "\n",
    "    if kind_of_index == \"1\":\n",
    "        calculate_dunn_index()\n",
    "    elif kind_of_index == \"2\":\n",
    "        calculate_davies_bouldin_index()\n",
    "    else:\n",
    "        raise ValueError(\"Pod tym numerem nie ma indeksu miary!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
